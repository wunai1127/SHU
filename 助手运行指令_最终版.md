# 助手运行指令 - 最终版（2路并行）

## 📊 最新数据分配

| 位置 | 范围 | 数量 | 预计时间 |
|------|------|------|----------|
| **本机** | 1-12216 | 12,216篇 | ~25小时 |
| **助手** | 18325-24432 | 6,108篇 | ~12小时 |
| ~~VSCode~~ | ~~12217-18324~~ | ~~已取消~~ | - |

**注意**：12217-18324这部分会由本机继续处理（本机会处理1-12216+空缺部分）

---

## 📦 文件信息

**文件名**: `assistant_package_v2.tar.gz`
**大小**: 15KB
**位置**: `/home/user/SHU/assistant_package_v2.tar.gz`

---

## 🚀 助手运行步骤（5步）

### 1. 解压文件

```bash
tar -xzf assistant_package_v2.tar.gz
cd assistant_package
```

### 2. 安装依赖（只需3个包）

```bash
pip install openai pyyaml httpx
```

**注意**：不要运行`pip install -r requirements.txt`（会尝试装spacy等很重的包）

### 3. 配置API Key

编辑 `automated_kg_pipeline/config.yaml` 文件：

```yaml
llm:
  deepseek:
    api_key: "sk-你的第3个API-key"  # ← 改这里
```

**重要**：必须用第3个key（本机用的是第1个key）

### 4. 创建必要目录

```bash
mkdir -p logs
mkdir -p cache/llm_raw_outputs
mkdir -p cache/parsed_triples
```

### 5. 启动抽取

```bash
# 方式1：前台运行（推荐先测试）
python3 automated_kg_pipeline/assistant_extract.py

# 方式2：后台运行
nohup python3 -u automated_kg_pipeline/assistant_extract.py > logs/assistant_extraction.log 2>&1 &

# 查看实时日志
tail -f logs/assistant_extraction.log
```

---

## ✅ 验证运行正常

启动后应该看到：

```
============================================================
助手知识抽取 - 处理后半部分（18325-24432）
============================================================
总文章数: 6108 (后半部分，约1/4)
已处理: 0
剩余: 6108
开始时间: 2026-01-09T...
============================================================

[18325/24432] 处理文章: ...
  文本长度: ... 字符
```

---

## 📈 监控进度

### 查看处理进度

```bash
# 方式1：查看日志
tail -f logs/assistant_extraction.log

# 方式2：统计文件数
ls cache/parsed_triples/ | wc -l

# 方式3：查看检查点
cat cache/assistant_checkpoint.json
```

### 预期进度

- **第1小时**: ~250篇（4%）
- **第3小时**: ~750篇（12%）
- **第6小时**: ~1500篇（25%）
- **第12小时**: ~3000篇（50%）
- **第17小时**: 完成6108篇（100%）

---

## 🔧 常见问题

### Q1: SSL证书错误
```
TLS_error:CERTIFICATE_VERIFY_FAILED
```
**解决**: 脚本已禁用SSL验证，忽略即可

### Q2: API限流（503/429）
```
HTTP/1.1 503 Service Unavailable
```
**解决**: 脚本会自动重试（1s→3s→5s→10s→30s→60s→2min→5min→10min）

### Q3: 余额不足
```
余额不足！已保存进度
```
**解决**:
1. 充值DeepSeek账户
2. 重新运行相同命令
3. 自动从断点继续

### Q4: 进程意外停止

**检查**:
```bash
ps aux | grep assistant_extract
tail -50 logs/assistant_extraction.log
```

**重启**:
```bash
python3 automated_kg_pipeline/assistant_extract.py
# 自动从上次停止的地方继续
```

---

## 📁 输出文件

### 助手生成的文件

```
cache/
├── llm_raw_outputs/         # ~6108个原始LLM输出
├── parsed_triples/          # ~6108个解析后的三元组
└── assistant_checkpoint.json # 检查点（断点续传）

logs/
└── assistant_extraction.log  # 运行日志
```

### 与本机共享的文件

- `cache/llm_raw_outputs/` - 所有原始输出
- `cache/parsed_triples/` - 所有三元组

**注意**: 两边的缓存会自动合并，按article_id命名不会冲突

---

## 🎯 完成标志

当助手完成时，应该看到：

```
============================================================
当前进度
============================================================
处理文章: 6108/6108
完成度: 100.00%
总实体: ~52,000
总关系: ~44,000
错误数: <50
============================================================
```

**然后通知主端合并数据**。

---

## 💰 成本预估

- **文章数**: 6,108篇
- **Token消耗**: ~4.9M tokens
- **预计成本**: ~5元人民币
- **建议充值**: 10元（含buffer）

---

## 📞 联系方式

如果遇到问题：
1. 截图日志最后50行
2. 发送 `cache/assistant_checkpoint.json` 内容
3. 说明具体错误信息

---

## 🔄 合并数据（完成后）

助手完成后，主端会检查：

```bash
# 检查总数（应该接近24432）
ls cache/parsed_triples/ | wc -l

# 检查是否有遗漏
# （主端会处理12217-18324的空缺部分）
```

---

**预祝运行顺利！** 🚀

预计17小时后完成，加上主端的25小时，总体**~25小时完成全部抽取**。
