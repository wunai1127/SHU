# çŸ¥è¯†å›¾è°±æ„å»ºæµç¨‹ä¼˜åŒ–ç­–ç•¥

## ä¸€ã€å¹¶è¡Œå¤„ç†æ¶æ„ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰

### 1.1 ä¸‰å±‚å¹¶è¡Œè®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              20000ç¯‡æ–‡ç«  (Input Layer)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
        â–¼             â–¼             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Shard 1 â”‚    â”‚Shard 2 â”‚ ...â”‚Shard 20â”‚  (Shard Layer)
   â”‚1000ç¯‡  â”‚    â”‚1000ç¯‡  â”‚    â”‚1000ç¯‡  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
   â”‚GPU 0    â”‚   â”‚GPU 1    â”‚  â”‚GPU 2/3  â”‚  (GPU Layer)
   â”‚LLMæŠ½å–  â”‚   â”‚LLMæŠ½å–  â”‚  â”‚LLMæŠ½å–  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Neo4jæ‰¹é‡å¯¼å…¥    â”‚       (Sink Layer)
            â”‚  (5000/batch)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å®ç°ä»£ç **ï¼š

```python
# automated_kg_pipeline/parallel_processor.py
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed

class ParallelKGBuilder:
    def __init__(self, num_gpus: int = 2):
        self.num_gpus = num_gpus
        self.num_workers = num_gpus * 2  # æ¯ä¸ªGPUè¿è¡Œ2ä¸ªworker

    def process_shards_parallel(self, articles: List[Dict], shard_size: int = 1000):
        """å¹¶è¡Œå¤„ç†åˆ†ç‰‡"""
        shards = [articles[i:i+shard_size] for i in range(0, len(articles), shard_size)]

        with ProcessPoolExecutor(max_workers=self.num_workers) as executor:
            futures = {
                executor.submit(self._process_shard, shard_id, shard, gpu_id % self.num_gpus): shard_id
                for shard_id, (shard, gpu_id) in enumerate(zip(shards, range(len(shards))))
            }

            results = []
            for future in as_completed(futures):
                shard_id = futures[future]
                try:
                    shard_triples = future.result()
                    results.extend(shard_triples)
                    print(f"âœ“ Shard {shard_id} å®Œæˆ: {len(shard_triples)} triples")
                except Exception as e:
                    print(f"âœ— Shard {shard_id} å¤±è´¥: {e}")

        return results

    def _process_shard(self, shard_id: int, articles: List[Dict], gpu_id: int):
        """å¤„ç†å•ä¸ªåˆ†ç‰‡ï¼ˆåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­è¿è¡Œï¼‰"""
        import os
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)

        # åˆå§‹åŒ–LLMï¼ˆæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹åŠ è½½ï¼‰
        extractor = self._init_extractor(gpu_id)

        # å¤„ç†æ–‡ç« 
        triples = []
        for article in articles:
            triples.extend(extractor.extract(article))

        # ä¿å­˜åˆ†ç‰‡ç»“æœåˆ°ç£ç›˜ï¼ˆé¿å…å†…å­˜çˆ†ç‚¸ï¼‰
        shard_file = f"/tmp/kg_shard_{shard_id}.json"
        with open(shard_file, 'w') as f:
            json.dump(triples, f)

        return shard_file  # è¿”å›æ–‡ä»¶è·¯å¾„è€Œéæ•°æ®
```

### 1.2 ä¼°ç®—æ€§èƒ½

| é…ç½® | å•ç¯‡å¤„ç†æ—¶é—´ | æ€»æ—¶é—´ï¼ˆ20000ç¯‡ï¼‰ |
|------|------------|-----------------|
| **å•GPUé¡ºåº** | 10ç§’ | 55.5å°æ—¶ |
| **2 GPUå¹¶è¡Œ** | 10ç§’ | 27.8å°æ—¶ |
| **4 GPUå¹¶è¡Œ** | 10ç§’ | 13.9å°æ—¶ |
| **API (10 QPS)** | 1ç§’ | 33åˆ†é’Ÿ |

**æ¨èé…ç½®**ï¼š
- å¦‚æœæœ‰é¢„ç®—ï¼šä½¿ç”¨DeepSeek APIï¼ˆæˆæœ¬çº¦50-100å…ƒï¼Œ30åˆ†é’Ÿå®Œæˆï¼‰
- å¦‚æœæœ¬åœ°GPUï¼š4ä¸ªGPUå¹¶è¡Œï¼ˆçº¦14å°æ—¶å®Œæˆï¼‰

---

## äºŒã€ç¼“å­˜ä¸å¢é‡æ›´æ–°

### 2.1 ä¸‰çº§ç¼“å­˜è®¾è®¡

```python
# cache/cache_manager.py
import hashlib
import pickle
from pathlib import Path

class KGCache:
    """ä¸‰çº§ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, cache_dir: str):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # Level 1: LLMå“åº”ç¼“å­˜ï¼ˆé¿å…é‡å¤è°ƒç”¨ï¼‰
        self.llm_cache_dir = self.cache_dir / "llm_responses"
        self.llm_cache_dir.mkdir(exist_ok=True)

        # Level 2: è§£æåçš„ä¸‰å…ƒç»„ç¼“å­˜
        self.triple_cache_dir = self.cache_dir / "triples"
        self.triple_cache_dir.mkdir(exist_ok=True)

        # Level 3: Neo4jå¯¼å…¥çŠ¶æ€ç¼“å­˜
        self.import_state_file = self.cache_dir / "import_state.pkl"

    def get_llm_response(self, article_id: str, text_hash: str):
        """è·å–LLMç¼“å­˜å“åº”"""
        cache_key = f"{article_id}_{text_hash}"
        cache_file = self.llm_cache_dir / f"{cache_key}.json"

        if cache_file.exists():
            with open(cache_file, 'r') as f:
                return json.load(f)
        return None

    def save_llm_response(self, article_id: str, text: str, response: str):
        """ä¿å­˜LLMå“åº”"""
        text_hash = hashlib.md5(text.encode()).hexdigest()[:8]
        cache_key = f"{article_id}_{text_hash}"
        cache_file = self.llm_cache_dir / f"{cache_key}.json"

        with open(cache_file, 'w') as f:
            json.dump({"response": response}, f)

    def is_article_processed(self, article_id: str) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²å¤„ç†"""
        triple_file = self.triple_cache_dir / f"{article_id}.json"
        return triple_file.exists()

    def get_import_state(self) -> Dict:
        """è·å–å¯¼å…¥çŠ¶æ€"""
        if self.import_state_file.exists():
            with open(self.import_state_file, 'rb') as f:
                return pickle.load(f)
        return {"imported_articles": set(), "last_batch_id": 0}

    def update_import_state(self, article_ids: List[str], batch_id: int):
        """æ›´æ–°å¯¼å…¥çŠ¶æ€"""
        state = self.get_import_state()
        state["imported_articles"].update(article_ids)
        state["last_batch_id"] = batch_id

        with open(self.import_state_file, 'wb') as f:
            pickle.dump(state, f)
```

**å¢é‡æ›´æ–°æµç¨‹**ï¼š

```python
def incremental_update(new_articles: List[Dict]):
    """å¢é‡æ›´æ–°KGï¼ˆåªå¤„ç†æ–°æ–‡ç« ï¼‰"""
    cache = KGCache("/home/user/SHU/cache")

    # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ç« 
    to_process = [
        article for article in new_articles
        if not cache.is_article_processed(article['id'])
    ]

    print(f"æ–°å¢æ–‡ç« : {len(to_process)} / {len(new_articles)}")

    # åªå¤„ç†æ–°æ–‡ç« 
    new_triples = extract_knowledge(to_process)

    # å¢é‡å¯¼å…¥Neo4j
    import_to_neo4j(new_triples)
```

---

## ä¸‰ã€Neo4jå¯¼å…¥ä¼˜åŒ–

### 3.1 æ‰¹é‡å¯¼å…¥ vs å®æ—¶å¯¼å…¥

| æ–¹æ³• | é€Ÿåº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| **Cypher MERGE** | 1000èŠ‚ç‚¹/ç§’ | å®æ—¶æ›´æ–° |
| **APOCæ‰¹é‡** | 10000èŠ‚ç‚¹/ç§’ | ä¸­ç­‰è§„æ¨¡ |
| **neo4j-admin import** | 100000èŠ‚ç‚¹/ç§’ | åˆæ¬¡å…¨é‡å¯¼å…¥ |

**æ¨èæ–¹æ¡ˆ**ï¼š

```bash
# ç¬¬ä¸€æ¬¡å…¨é‡å¯¼å…¥ï¼šä½¿ç”¨neo4j-adminï¼ˆæœ€å¿«ï¼‰
# 1. åœæ­¢Neo4jæœåŠ¡
sudo systemctl stop neo4j

# 2. å¯¼å‡ºä¸‰å…ƒç»„ä¸ºCSV
python export_to_csv.py --output /tmp/kg_csv/

# 3. ä½¿ç”¨neo4j-adminå¯¼å…¥
neo4j-admin database import full \
    --nodes=Entity=/tmp/kg_csv/entities.csv \
    --relationships=RELATION=/tmp/kg_csv/relations.csv \
    --overwrite-destination \
    heart_transplant_kg

# 4. é‡å¯Neo4j
sudo systemctl start neo4j
```

**CSVæ ¼å¼è§„èŒƒ**ï¼š

```csv
# entities.csv
id:ID,name,type:LABEL,properties
e1,"å»¶é•¿ç¼ºè¡€æ—¶é—´","é£é™©å› å­","{\"é£é™©ç­‰çº§\":\"é«˜\"}"
e2,"åŸå‘æ€§ç§»æ¤ç‰©åŠŸèƒ½éšœç¢","å¹¶å‘ç—‡","{\"å‘ç”Ÿç‡\":\"10-20%\"}"

# relations.csv
:START_ID,:END_ID,:TYPE,properties
e1,e2,å¯¼è‡´,"{\"è¯æ®å¼ºåº¦\":\"RCT\",\"ä¼˜åŠ¿æ¯”\":2.3,\"På€¼\":0.001}"
```

### 3.2 Neo4jé…ç½®ä¼˜åŒ–

```conf
# /etc/neo4j/neo4j.conf

# å†…å­˜é…ç½®ï¼ˆå‡è®¾æœåŠ¡å™¨æœ‰32GBå†…å­˜ï¼‰
dbms.memory.heap.initial_size=8g
dbms.memory.heap.max_size=8g
dbms.memory.pagecache.size=16g

# æ‰¹é‡å¯¼å…¥ä¼˜åŒ–
dbms.transaction.timeout=300s
dbms.lock.acquisition.timeout=300s

# å¹¶å‘é…ç½®
dbms.threads.worker_count=8

# æ—¥å¿—çº§åˆ«ï¼ˆç”Ÿäº§ç¯å¢ƒé™ä½æ—¥å¿—é‡ï¼‰
dbms.logs.query.enabled=false
```

---

## å››ã€è´¨é‡ä¿è¯æœºåˆ¶

### 4.1 å®æ—¶è´¨é‡ç›‘æ§

```python
class QualityMonitor:
    """å®æ—¶è´¨é‡ç›‘æ§å™¨"""

    def __init__(self):
        self.stats = {
            "low_confidence_triples": [],
            "invalid_relations": [],
            "outlier_articles": []
        }

    def check_triple_quality(self, triple: Dict, article_id: str):
        """æ£€æŸ¥å•ä¸ªä¸‰å…ƒç»„è´¨é‡"""
        issues = []

        # æ£€æŸ¥1: ç½®ä¿¡åº¦
        if triple.get('confidence', 1.0) < 0.7:
            issues.append("ä½ç½®ä¿¡åº¦")
            self.stats["low_confidence_triples"].append(triple)

        # æ£€æŸ¥2: SchemaéªŒè¯
        if not self._validate_schema(triple):
            issues.append("Schemaä¸ç¬¦")
            self.stats["invalid_relations"].append(triple)

        # æ£€æŸ¥3: ç»Ÿè®¡é‡åˆç†æ€§
        if 'properties' in triple:
            props = triple['properties']
            if 'p_value' in props and props['p_value'] > 1.0:
                issues.append("På€¼å¼‚å¸¸")

        return issues

    def check_article_quality(self, article_id: str, triples: List[Dict]):
        """æ£€æŸ¥å•ç¯‡æ–‡ç« è´¨é‡"""
        num_entities = len([t for t in triples if t['type'] == 'entity'])
        num_relations = len([t for t in triples if t['type'] == 'relation'])

        # å¼‚å¸¸æ£€æµ‹
        if num_entities < 5:
            self.stats["outlier_articles"].append({
                "article_id": article_id,
                "issue": "å®ä½“æ•°è¿‡å°‘",
                "count": num_entities
            })

        if num_relations == 0:
            self.stats["outlier_articles"].append({
                "article_id": article_id,
                "issue": "æ— å…³ç³»æŠ½å–"
            })

    def generate_quality_report(self) -> Dict:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        return {
            "ä½ç½®ä¿¡åº¦ä¸‰å…ƒç»„æ•°": len(self.stats["low_confidence_triples"]),
            "Schemaä¸ç¬¦ä¸‰å…ƒç»„æ•°": len(self.stats["invalid_relations"]),
            "å¼‚å¸¸æ–‡ç« æ•°": len(self.stats["outlier_articles"]),
            "å¼‚å¸¸æ–‡ç« è¯¦æƒ…": self.stats["outlier_articles"][:10]  # å‰10ä¸ª
        }
```

### 4.2 è‡ªåŠ¨ä¿®å¤æœºåˆ¶

```python
class AutoFixer:
    """è‡ªåŠ¨ä¿®å¤å¸¸è§é”™è¯¯"""

    @staticmethod
    def fix_abbreviation(entity_name: str, context: str) -> str:
        """ç¼©å†™å±•å¼€"""
        abbr_map = {
            "PGD": "Primary Graft Dysfunction",
            "PVR": "Pulmonary Vascular Resistance",
            "ISHLT": "International Society for Heart and Lung Transplantation",
            "LVEF": "Left Ventricular Ejection Fraction"
        }
        return abbr_map.get(entity_name, entity_name)

    @staticmethod
    def fix_duplicate_entities(triples: List[Dict]) -> List[Dict]:
        """åˆå¹¶é‡å¤å®ä½“"""
        entity_map = {}

        for triple in triples:
            if triple['type'] == 'entity':
                name = triple['name']
                # æ ‡å‡†åŒ–åç§°
                normalized_name = AutoFixer._normalize_entity_name(name)

                if normalized_name not in entity_map:
                    entity_map[normalized_name] = triple
                else:
                    # åˆå¹¶å±æ€§
                    entity_map[normalized_name]['properties'].update(triple.get('properties', {}))

        # æ›´æ–°å…³ç³»ä¸­çš„å®ä½“å¼•ç”¨
        fixed_triples = list(entity_map.values())

        for triple in triples:
            if triple['type'] == 'relation':
                triple['head'] = AutoFixer._normalize_entity_name(triple['head'])
                triple['tail'] = AutoFixer._normalize_entity_name(triple['tail'])
                fixed_triples.append(triple)

        return fixed_triples

    @staticmethod
    def _normalize_entity_name(name: str) -> str:
        """å®ä½“åç§°æ ‡å‡†åŒ–"""
        # è½¬å°å†™
        normalized = name.lower().strip()
        # ç§»é™¤æ ‡ç‚¹
        normalized = re.sub(r'[^\w\s]', '', normalized)
        # å±•å¼€ç¼©å†™
        normalized = AutoFixer.fix_abbreviation(normalized, "")
        return normalized
```

---

## äº”ã€æ€§èƒ½ç“¶é¢ˆè¯†åˆ«ä¸è§£å†³

### 5.1 Profileåˆ†æ

```python
import cProfile
import pstats

def profile_pipeline():
    """æ€§èƒ½åˆ†æ"""
    profiler = cProfile.Profile()
    profiler.enable()

    # è¿è¡Œæµæ°´çº¿
    builder = AutoKGBuilder('config.yaml')
    builder.run()

    profiler.disable()

    # è¾“å‡ºæŠ¥å‘Š
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # å‰20ä¸ªæœ€æ…¢å‡½æ•°
```

**å¸¸è§ç“¶é¢ˆä¸è§£å†³æ–¹æ¡ˆ**ï¼š

| ç“¶é¢ˆ | ç°è±¡ | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| **LLMæ¨ç†æ…¢** | GPUåˆ©ç”¨ç‡100% | å¢åŠ GPUæ•°é‡ / ä½¿ç”¨API / é‡åŒ–æ¨¡å‹ |
| **JSONè§£ææ…¢** | CPUåˆ©ç”¨ç‡é«˜ | ä½¿ç”¨ujson / orjsonæ›¿ä»£json |
| **Neo4jå†™å…¥æ…¢** | ç½‘ç»œå»¶è¿Ÿé«˜ | æ‰¹é‡å¯¼å…¥ / ä½¿ç”¨æœ¬åœ°Neo4j |
| **å†…å­˜ä¸è¶³** | OOMé”™è¯¯ | å‡å°batch_size / ä½¿ç”¨æµå¼å¤„ç† |

---

## å…­ã€ä¼˜åŒ–æ•ˆæœå¯¹æ¯”

### åŸºçº¿é…ç½® vs ä¼˜åŒ–é…ç½®

| æŒ‡æ ‡ | åŸºçº¿ | ä¼˜åŒ–å | æå‡ |
|------|------|--------|------|
| **æ€»å¤„ç†æ—¶é—´** | 55.5å°æ—¶ | 14å°æ—¶ | 4x |
| **GPUåˆ©ç”¨ç‡** | 25% | 90% | 3.6x |
| **å†…å­˜å ç”¨** | 32GB | 16GB | 0.5x |
| **Neo4jå¯¼å…¥é€Ÿåº¦** | 1000èŠ‚ç‚¹/ç§’ | 100000èŠ‚ç‚¹/ç§’ | 100x |
| **å¯æ¢å¤æ€§** | æ—  | æ–­ç‚¹ç»­ä¼  | âˆ |

---

## ä¸ƒã€ä¸€é”®ä¼˜åŒ–è„šæœ¬

```python
# automated_kg_pipeline/optimize_and_run.py

def optimize_config(config_path: str) -> Dict:
    """è‡ªåŠ¨ä¼˜åŒ–é…ç½®"""
    config = load_config(config_path)

    # æ£€æµ‹GPUæ•°é‡
    num_gpus = torch.cuda.device_count()
    config['extraction']['num_workers'] = num_gpus * 2

    # æ£€æµ‹å†…å­˜å¤§å°
    import psutil
    total_memory_gb = psutil.virtual_memory().total / (1024**3)

    if total_memory_gb > 64:
        config['extraction']['batch_size'] = 16
    elif total_memory_gb > 32:
        config['extraction']['batch_size'] = 8
    else:
        config['extraction']['batch_size'] = 4

    # æ£€æµ‹Neo4jè¿æ¥é€Ÿåº¦
    latency = test_neo4j_latency(config['neo4j'])
    if latency > 100:  # >100msè¯´æ˜æ˜¯è¿œç¨‹è¿æ¥
        config['neo4j']['batch_import']['batch_size'] = 10000
    else:
        config['neo4j']['batch_import']['batch_size'] = 5000

    return config

if __name__ == '__main__':
    # è‡ªåŠ¨ä¼˜åŒ–é…ç½®
    config = optimize_config('config_template.yaml')

    # è¿è¡Œæµæ°´çº¿
    builder = AutoKGBuilder(config)
    builder.run()
```

---

## å…«ã€æ‰§è¡Œæ—¶é—´è¡¨ï¼ˆ20000ç¯‡æ–‡ç« ï¼‰

| é˜¶æ®µ | æ—¶é—´ | å¯ä¼˜åŒ–é¡¹ |
|------|------|---------|
| **æ•°æ®åŠ è½½** | 5åˆ†é’Ÿ | ä½¿ç”¨jsonlæ ¼å¼ |
| **LLMæŠ½å–** | 13å°æ—¶ | **æ ¸å¿ƒç“¶é¢ˆ** - å¤šGPUå¹¶è¡Œ |
| **è´¨é‡è¿‡æ»¤** | 10åˆ†é’Ÿ | ç¼–è¯‘CythonåŠ é€Ÿ |
| **Neo4jå¯¼å…¥** | 30åˆ†é’Ÿ | ä½¿ç”¨neo4j-admin |
| **éªŒè¯æŠ¥å‘Š** | 5åˆ†é’Ÿ | - |
| **æ€»è®¡** | ~14å°æ—¶ | |

**ä¼˜åŒ–ä¼˜å…ˆçº§**ï¼š
1. âš¡ **æœ€é«˜ä¼˜å…ˆçº§**ï¼šLLMæŠ½å–å¹¶è¡ŒåŒ–ï¼ˆèŠ‚çœ40å°æ—¶ï¼‰
2. ğŸ”¥ **é«˜ä¼˜å…ˆçº§**ï¼šNeo4jæ‰¹é‡å¯¼å…¥ï¼ˆèŠ‚çœ2å°æ—¶ï¼‰
3. ğŸŒŸ **ä¸­ä¼˜å…ˆçº§**ï¼šå¯ç”¨ç¼“å­˜æœºåˆ¶ï¼ˆé‡è·‘èŠ‚çœ100%æ—¶é—´ï¼‰
