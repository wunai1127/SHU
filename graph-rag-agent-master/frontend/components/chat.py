import streamlit as st
import uuid
import re
import json
import traceback
from utils.api import send_message, send_feedback, get_source_content, get_knowledge_graph_from_message, get_source_file_info_batch, clear_chat, send_message_stream
from utils.helpers import extract_source_ids

def reset_processing_lock():
    """é‡ç½®å¤„ç†é”çŠ¶æ€"""
    st.session_state.processing_lock = False

def display_chat_interface():
    """æ˜¾ç¤ºä¸»èŠå¤©ç•Œé¢"""
    st.title("GraphRAG å¯¹è¯ç³»ç»Ÿ")
    
    # ç¡®ä¿é”å˜é‡å­˜åœ¨å¹¶è®¾åˆå§‹å€¼ï¼Œå¦‚æœä¸å­˜åœ¨çš„è¯
    if "processing_lock" not in st.session_state:
        st.session_state.processing_lock = False
    
    # è®¾ç½®æ 
    with st.container():
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            # æ·»åŠ é‡ç½®é”çš„åŠŸèƒ½åˆ° selectbox çš„ on_change å‚æ•°
            previous_agent = st.session_state.agent_type
            agent_type = st.selectbox(
                "é€‰æ‹© Agent ç±»å‹",
                options=["graph_agent", "hybrid_agent", "naive_rag_agent", "deep_research_agent", "fusion_agent"],
                key="header_agent_type",
                help="é€‰æ‹©ä¸åŒçš„Agentä»¥ä½“éªŒä¸åŒçš„æ£€ç´¢ç­–ç•¥",
                index=0 if st.session_state.agent_type == "graph_agent" 
                        else (1 if st.session_state.agent_type == "hybrid_agent" 
                             else (2 if st.session_state.agent_type == "naive_rag_agent"
                                  else (3 if st.session_state.agent_type == "deep_research_agent"
                                       else 4))),
                on_change=reset_processing_lock
            )
            
            # æ£€æŸ¥æ˜¯å¦åˆ‡æ¢äº†agentç±»å‹
            if previous_agent != agent_type:
                # åˆ‡æ¢agentç±»å‹æ—¶é‡ç½®é”
                st.session_state.processing_lock = False
                
            st.session_state.agent_type = agent_type
            
            # æ·»åŠ æ€è€ƒè¿‡ç¨‹åˆ‡æ¢ - ä»…å½“é€‰æ‹© deep_research_agent æ—¶æ˜¾ç¤º
            if agent_type == "deep_research_agent":
                show_thinking = st.checkbox("æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹", 
                          value=st.session_state.get("show_thinking", False),
                          key="header_show_thinking",
                          help="æ˜¾ç¤ºAIçš„æ€è€ƒè¿‡ç¨‹",
                          on_change=reset_processing_lock)
                st.session_state.show_thinking = show_thinking

                use_deeper = st.checkbox("ä½¿ç”¨å¢å¼ºç‰ˆç ”ç©¶å·¥å…·", 
                                        value=st.session_state.get("use_deeper_tool", True),
                                        key="header_use_deeper",
                                        help="å¯ç”¨ç¤¾åŒºæ„ŸçŸ¥å’ŒçŸ¥è¯†å›¾è°±å¢å¼º",
                                        on_change=reset_processing_lock)
                st.session_state.use_deeper_tool = use_deeper
    
        with col2:
            # æ·»åŠ æµå¼å“åº”é€‰é¡¹ - ä»…å½“è°ƒè¯•æ¨¡å¼æœªå¯ç”¨æ—¶æ˜¾ç¤º
            if not st.session_state.debug_mode:
                use_stream = st.checkbox("ä½¿ç”¨æµå¼å“åº”", 
                                        value=st.session_state.get("use_stream", True),
                                        key="header_use_stream",
                                        help="å¯ç”¨æµå¼å“åº”ï¼Œå®æ—¶æ˜¾ç¤ºç”Ÿæˆç»“æœ",
                                        on_change=reset_processing_lock)
                st.session_state.use_stream = use_stream
            else:
                # åœ¨è°ƒè¯•æ¨¡å¼ä¸‹è‡ªåŠ¨ç¦ç”¨æµå¼å“åº”
                st.session_state.use_stream = False
                st.info("è°ƒè¯•æ¨¡å¼ä¸‹å·²ç¦ç”¨æµå¼å“åº”")
            
        with col3:
            # ä¿®æ”¹æ¸…é™¤èŠå¤©æŒ‰é’®ï¼Œæ·»åŠ é‡ç½®é”çš„åŠŸèƒ½
            st.button("ğŸ—‘ï¸ æ¸…é™¤èŠå¤©", key="header_clear_chat", on_click=clear_chat_with_lock_reset)
    
    # åˆ†éš”çº¿
    st.markdown("---")
    
    # å¦‚æœå½“å‰æœ‰æ­£åœ¨å¤„ç†çš„è¯·æ±‚ï¼Œæ˜¾ç¤ºè­¦å‘Š
    if st.session_state.processing_lock:
        st.warning("è¯·ç­‰å¾…å½“å‰æ“ä½œå®Œæˆ...")
        # æ·»åŠ å¼ºåˆ¶é‡ç½®é”çš„æŒ‰é’®
        if st.button("å¼ºåˆ¶é‡ç½®å¤„ç†çŠ¶æ€", key="force_reset_lock"):
            st.session_state.processing_lock = False
            st.rerun()
    
    # èŠå¤©åŒºåŸŸ
    chat_container = st.container()
    with chat_container:
        # æ˜¾ç¤ºç°æœ‰æ¶ˆæ¯
        for i, msg in enumerate(st.session_state.messages):
            with st.chat_message(msg["role"]):
                # è·å–è¦æ˜¾ç¤ºçš„å†…å®¹
                content = msg["content"]
                
                # å¤„ç†deep_research_agentçš„æ€è€ƒè¿‡ç¨‹
                if msg["role"] == "assistant":
                    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
                    show_thinking = (st.session_state.agent_type == "deep_research_agent" and 
                                    st.session_state.get("show_thinking", False))
                    
                    # ä¼˜å…ˆä½¿ç”¨raw_thinkingå­—æ®µ
                    if "raw_thinking" in msg and show_thinking:
                        # æå–æ€è€ƒè¿‡ç¨‹
                        thinking_process = msg["raw_thinking"]
                        answer_content = msg.get("processed_content", content)
                        
                        # æ ¼å¼åŒ–æ€è€ƒè¿‡ç¨‹ï¼Œä½¿ç”¨å¼•ç”¨æ ¼å¼
                        thinking_lines = thinking_process.split('\n')
                        quoted_thinking = '\n'.join([f"> {line}" for line in thinking_lines])
                        
                        # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
                        st.markdown(quoted_thinking)
                        
                        # æ·»åŠ ä¸¤è¡Œç©ºè¡Œé—´éš”
                        st.markdown("\n\n")
                        
                        # æ˜¾ç¤ºç­”æ¡ˆ
                        st.markdown(answer_content)
                    # æ£€æŸ¥æ˜¯å¦æœ‰<think>æ ‡ç­¾
                    elif "<think>" in content and "</think>" in content:
                        # æå–<think>æ ‡ç­¾ä¸­çš„å†…å®¹
                        thinking_match = re.search(r'<think>(.*?)</think>', content, re.DOTALL)
                        
                        if thinking_match:
                            thinking_process = thinking_match.group(1)
                            # ç§»é™¤æ€è€ƒè¿‡ç¨‹ï¼Œä¿ç•™ç­”æ¡ˆ
                            answer_content = content.replace(f"<think>{thinking_process}</think>", "").strip()
                            
                            if show_thinking:
                                # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼ˆä»…å½“show_thinkingä¸ºTrueæ—¶ï¼‰
                                # æ ¼å¼åŒ–æ€è€ƒè¿‡ç¨‹ï¼Œä½¿ç”¨å¼•ç”¨æ ¼å¼
                                thinking_lines = thinking_process.split('\n')
                                quoted_thinking = '\n'.join([f"> {line}" for line in thinking_lines])
                                
                                # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
                                st.markdown(quoted_thinking)
                                
                                # æ·»åŠ ä¸¤è¡Œç©ºè¡Œé—´éš”
                                st.markdown("\n\n")
                                
                                # æ˜¾ç¤ºç­”æ¡ˆ
                                st.markdown(answer_content)
                            else:
                                # åªæ˜¾ç¤ºç­”æ¡ˆéƒ¨åˆ†ï¼ˆä¸æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼‰
                                st.markdown(answer_content)
                        else:
                            # å¦‚æœæå–å¤±è´¥ï¼Œæ˜¾ç¤ºå®Œæ•´å†…å®¹ä½†ç§»é™¤å¯èƒ½çš„<think>æ ‡ç­¾
                            cleaned_content = re.sub(r'<think>|</think>', '', content)
                            st.markdown(cleaned_content)
                    else:
                        # æ™®é€šå›ç­”ï¼Œæ— æ€è€ƒè¿‡ç¨‹
                        st.markdown(content)
                else:
                    # æ™®é€šæ¶ˆæ¯ç›´æ¥æ˜¾ç¤º
                    st.markdown(content)
                
                # ä¸ºAIå›ç­”æ·»åŠ åé¦ˆæŒ‰é’®å’Œæºå†…å®¹å¼•ç”¨
                if msg["role"] == "assistant":
                    # ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„æ¶ˆæ¯ID (å¦‚æœä¹‹å‰æ²¡æœ‰)
                    if "message_id" not in msg:
                        msg["message_id"] = str(uuid.uuid4())
                        
                    # æŸ¥æ‰¾å¯¹åº”çš„ç”¨æˆ·é—®é¢˜
                    user_query = ""
                    if i > 0 and st.session_state.messages[i-1]["role"] == "user":
                        user_query = st.session_state.messages[i-1]["content"]
                        
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æä¾›è¿‡åé¦ˆ
                    feedback_key = f"{msg['message_id']}"
                    feedback_type_key = f"feedback_type_{feedback_key}"
                    
                    # åˆ›å»ºä¸€ä¸ªå®¹å™¨ç”¨äºæ˜¾ç¤ºåé¦ˆç»“æœ
                    feedback_container = st.empty()
                    
                    if feedback_key not in st.session_state.feedback_given:
                        # æ·»åŠ åé¦ˆæŒ‰é’®
                        col1, col2, col3 = st.columns([0.1, 0.1, 0.8])
                        
                        with col1:
                            thumbs_up_key = f"thumbs_up_{msg['message_id']}_{i}"
                            if st.button("ğŸ‘", key=thumbs_up_key):
                                # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨å¤„ç†çš„è¯·æ±‚
                                if "feedback_in_progress" not in st.session_state:
                                    st.session_state.feedback_in_progress = False
                                
                                if st.session_state.feedback_in_progress:
                                    with feedback_container:
                                        st.warning("è¯·ç­‰å¾…å½“å‰æ“ä½œå®Œæˆ...")
                                else:
                                    st.session_state.feedback_in_progress = True
                                    try:
                                        with feedback_container:
                                            with st.spinner("æ­£åœ¨æäº¤åé¦ˆ..."):
                                                response = send_feedback(
                                                    msg["message_id"], 
                                                    user_query, 
                                                    True, 
                                                    st.session_state.session_id,
                                                    st.session_state.agent_type
                                                )
                                        
                                        st.session_state.feedback_given.add(feedback_key)
                                        st.session_state[feedback_type_key] = "positive"
                                        
                                        # æ ¹æ®å“åº”æ˜¾ç¤ºä¸åŒçš„æ¶ˆæ¯
                                        with feedback_container:
                                            if response and "action" in response:
                                                if "é«˜è´¨é‡" in response["action"]:
                                                    st.success("æ„Ÿè°¢æ‚¨çš„è‚¯å®šï¼æ­¤å›ç­”å·²è¢«æ ‡è®°ä¸ºé«˜è´¨é‡ã€‚", icon="ğŸ™‚")
                                                else:
                                                    st.success("æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼", icon="ğŸ‘")
                                            else:
                                                st.info("å·²æ”¶åˆ°æ‚¨çš„åé¦ˆã€‚", icon="â„¹ï¸")
                                    except Exception as e:
                                        st.error(f"æäº¤åé¦ˆæ—¶å‡ºé”™: {str(e)}")
                                    finally:                                           
                                        st.session_state.feedback_in_progress = False
                                    
                        with col2:
                            thumbs_down_key = f"thumbs_down_{msg['message_id']}_{i}"
                            if st.button("ğŸ‘", key=thumbs_down_key):
                                # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨å¤„ç†çš„è¯·æ±‚
                                if "feedback_in_progress" not in st.session_state:
                                    st.session_state.feedback_in_progress = False
                                
                                if st.session_state.feedback_in_progress:
                                    with feedback_container:
                                        st.warning("è¯·ç­‰å¾…å½“å‰æ“ä½œå®Œæˆ...")
                                else:
                                    st.session_state.feedback_in_progress = True
                                    try:
                                        with feedback_container:
                                            with st.spinner("æ­£åœ¨æäº¤åé¦ˆ..."):
                                                response = send_feedback(
                                                    msg["message_id"], 
                                                    user_query, 
                                                    False, 
                                                    st.session_state.session_id,
                                                    st.session_state.agent_type
                                                )
                                        
                                        st.session_state.feedback_given.add(feedback_key)
                                        st.session_state[feedback_type_key] = "negative"
                                        
                                        # æ ¹æ®å“åº”æ˜¾ç¤ºä¸åŒçš„æ¶ˆæ¯
                                        with feedback_container:
                                            if response and "action" in response:
                                                if "æ¸…é™¤" in response["action"]:
                                                    st.error("å·²æ”¶åˆ°æ‚¨çš„åé¦ˆï¼Œæ­¤å›ç­”å°†ä¸å†ä½¿ç”¨ã€‚", icon="ğŸ”„")
                                                else:
                                                    st.error("å·²æ”¶åˆ°æ‚¨çš„åé¦ˆï¼Œæˆ‘ä»¬ä¼šæ”¹è¿›ã€‚", icon="ğŸ‘")
                                            else:
                                                st.info("å·²æ”¶åˆ°æ‚¨çš„åé¦ˆã€‚", icon="â„¹ï¸")
                                    except Exception as e:
                                        st.error(f"æäº¤åé¦ˆæ—¶å‡ºé”™: {str(e)}")
                                    finally:
                                        st.session_state.feedback_in_progress = False
                    else:
                        # æ˜¾ç¤ºå·²æä¾›çš„åé¦ˆç±»å‹
                        feedback_type = st.session_state.get(feedback_type_key, None)
                        with feedback_container:
                            if feedback_type == "positive":
                                st.success("æ‚¨å·²å¯¹æ­¤å›ç­”ç»™äºˆè‚¯å®šï¼", icon="ğŸ‘")
                            elif feedback_type == "negative":
                                st.error("æ‚¨å·²å¯¹æ­¤å›ç­”æå‡ºæ”¹è¿›å»ºè®®ã€‚", icon="ğŸ‘")
                            else:
                                st.info("å·²æ”¶åˆ°æ‚¨çš„åé¦ˆã€‚", icon="â„¹ï¸")
                
                    # å¦‚æœæ˜¯AIå›ç­”ä¸”æœ‰æºå†…å®¹å¼•ç”¨ï¼Œæ˜¾ç¤ºæŸ¥çœ‹æºå†…å®¹æŒ‰é’®
                    if st.session_state.debug_mode and st.session_state.agent_type != "deep_research_agent":
                        source_ids = extract_source_ids(msg["content"])
                        if source_ids:
                            with st.expander("æŸ¥çœ‹å¼•ç”¨æºæ–‡æœ¬", expanded=False):
                                # è·å–æ‰€æœ‰æºæ–‡ä»¶ä¿¡æ¯
                                source_infos = get_source_file_info_batch(source_ids)
                                
                                for s_idx, source_id in enumerate(source_ids):
                                    # ä½¿ç”¨ç¼“å­˜çš„ä¿¡æ¯
                                    display_name = source_infos.get(source_id, {}).get("file_name", f"æºæ–‡æœ¬ {source_id}")
                                    source_btn_key = f"src_{source_id}_{i}_{s_idx}"
                                    
                                    if st.button(f"åŠ è½½ {display_name}", key=source_btn_key):
                                        with st.spinner(f"åŠ è½½æºæ–‡æœ¬ {display_name}..."):
                                            source_data = get_source_content(source_id)
                                            if source_data and "content" in source_data:
                                                st.session_state.source_content = source_data["content"]
                                                st.session_state.current_tab = "æºå†…å®¹"
                                                st.rerun()
                        
                        # å¦‚æœæ˜¯æœ€åä¸€æ¡AIæ¶ˆæ¯ï¼Œæ·»åŠ è‡ªåŠ¨æå–å›¾è°±æŒ‰é’® - deep_research_agentç¦ç”¨æ­¤åŠŸèƒ½
                        if st.session_state.agent_type != "deep_research_agent":
                            extract_kg_key = f"extract_kg_{i}"
                            if st.button("æå–çŸ¥è¯†å›¾è°±", key=extract_kg_key):
                                with st.spinner("æå–çŸ¥è¯†å›¾è°±æ•°æ®..."):
                                    # è·å–å¯¹åº”çš„ç”¨æˆ·æŸ¥è¯¢
                                    user_query = ""
                                    if i > 0 and st.session_state.messages[i-1]["role"] == "user":
                                        user_query = st.session_state.messages[i-1]["content"]
                                        
                                    # ä½¿ç”¨ç”¨æˆ·æŸ¥è¯¢æ¥è¿‡æ»¤çŸ¥è¯†å›¾è°±
                                    kg_data = get_knowledge_graph_from_message(msg["content"], user_query)
                                    if kg_data and len(kg_data.get("nodes", [])) > 0:
                                        # ç¡®ä¿å½“å‰æ¶ˆæ¯æœ‰æ­£ç¡®çš„kg_data
                                        st.session_state.messages[i]["kg_data"] = kg_data
                                        # æ›´æ–°å½“å‰çš„å›¾è°±æ¶ˆæ¯ç´¢å¼•ä¸ºå½“å‰å¤„ç†çš„æ¶ˆæ¯ç´¢å¼•
                                        st.session_state.current_kg_message = i
                                        st.session_state.current_tab = "çŸ¥è¯†å›¾è°±"  # è‡ªåŠ¨åˆ‡æ¢åˆ°çŸ¥è¯†å›¾è°±æ ‡ç­¾
                                        st.rerun()
        
        # å¤„ç†æ–°æ¶ˆæ¯
        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", key="chat_input"):
            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨å¤„ç†çš„è¯·æ±‚
            if "processing_lock" not in st.session_state:
                st.session_state.processing_lock = False
                
            if st.session_state.processing_lock:
                st.warning("è¯·ç­‰å¾…å½“å‰æ“ä½œå®Œæˆ...")
                return
                
            st.session_state.processing_lock = True
            
            with st.chat_message("user"):
                st.write(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            with st.chat_message("assistant"):
                try:
                    # åˆå§‹åŒ–æµå¼å“åº”çš„å ä½ç¬¦
                    message_placeholder = st.empty()
                    full_response = ""
                    thinking_content = ""
                    
                    # æ£€æŸ¥æµå¼å“åº”æ˜¯å¦å¯ç”¨ (å½“è°ƒè¯•æ¨¡å¼ç¦ç”¨æ—¶)
                    use_stream = st.session_state.get("use_stream", True) and not st.session_state.debug_mode
                    
                    if use_stream:
                        # å®šä¹‰ä»¤ç‰Œå¤„ç†å™¨
                        def handle_token(token, is_thinking=False):
                            nonlocal full_response, thinking_content
                            try:
                                # æ£€æŸ¥tokenæ˜¯å¦æ˜¯JSONå­—ç¬¦ä¸²
                                if isinstance(token, str) and token.startswith("{") and token.endswith("}"):
                                    try:
                                        import json
                                        # å°è¯•è§£æJSON
                                        json_data = json.loads(token)
                                        if "content" in json_data:
                                            token = json_data["content"]
                                        elif "status" in json_data:
                                            # è·³è¿‡çŠ¶æ€æ¶ˆæ¯
                                            return
                                    except json.JSONDecodeError as json_error:
                                        # ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œä¿æŒåŸæ ·
                                        print(f"JSONè§£æé”™è¯¯: {str(json_error)}")
                                        pass
                                
                                if is_thinking:
                                    # æ·»åŠ åˆ°æ€è€ƒå†…å®¹
                                    thinking_content += token
                                    # å°†æ€è€ƒå†…å®¹æ ¼å¼åŒ–ä¸ºå¼•ç”¨æ–‡æœ¬
                                    thinking_lines = thinking_content.split('\n')
                                    quoted_thinking = '\n'.join([f"> {line}" for line in thinking_lines])
                                    # åœ¨å ä½ç¬¦ä¸­æ˜¾ç¤º
                                    message_placeholder.markdown(quoted_thinking)
                                else:
                                    # æ·»åŠ åˆ°å®Œæ•´å“åº”
                                    full_response += token
                                    # åœ¨å ä½ç¬¦ä¸­æ˜¾ç¤ºï¼Œæ·»åŠ å…‰æ ‡æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
                                    message_placeholder.markdown(full_response + "â–Œ")
                            except Exception as e:
                                print(f"å¤„ç†ä»¤ç‰Œå‡ºé”™: {str(e)}")
                        
                        # ä½¿ç”¨æµå¼ API
                        with st.spinner("æ€è€ƒä¸­..."):
                            try:
                                raw_thinking = send_message_stream(prompt, handle_token)
                                # æ£€æŸ¥æ˜¯å¦æœ‰å“åº”
                                if not full_response or full_response.startswith("{") and full_response.endswith("}"):
                                    print("æµå¼å“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨éæµå¼API")
                                    response = send_message(prompt)
                                    if response:
                                        full_response = response.get("answer", "")
                                        message_placeholder.markdown(full_response)
                            except Exception as e:
                                print(f"æµå¼APIå¤±è´¥: {str(e)}")
                                response = send_message(prompt)
                                if response:
                                    full_response = response.get("answer", "")
                                    message_placeholder.markdown(full_response)
                        
                        # æœ€åä¸€æ¬¡æ›´æ–°ï¼Œç§»é™¤å…‰æ ‡
                        message_placeholder.markdown(full_response)
                        
                        # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡
                        message_obj = {
                            "role": "assistant",
                            "content": full_response,
                            "message_id": str(uuid.uuid4())
                        }
                        
                        # å¦‚æœæœ‰æ€è€ƒå†…å®¹ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                        if thinking_content:
                            message_obj["raw_thinking"] = thinking_content
                            message_obj["processed_content"] = full_response
                    else:
                        # ä½¿ç”¨éæµå¼ API
                        with st.spinner("æ€è€ƒä¸­..."):
                            response = send_message(prompt)
                        
                        if response:
                            answer = response.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚")
                            
                            # åœ¨å ä½ç¬¦ä¸­æ˜¾ç¤ºå†…å®¹
                            message_placeholder.markdown(answer)
                            
                            # åˆ›å»ºæ¶ˆæ¯å¯¹è±¡
                            message_obj = {
                                "role": "assistant", 
                                "content": answer,
                                "message_id": str(uuid.uuid4())
                            }
                            
                            # å¦‚æœæœ‰æ€è€ƒå†…å®¹ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                            if "raw_thinking" in response:
                                message_obj["raw_thinking"] = response["raw_thinking"]
                                message_obj["processed_content"] = answer
                                
                            # æ·»åŠ æ‰§è¡Œè½¨è¿¹åˆ°æ¶ˆæ¯å¯¹è±¡
                            if "execution_log" in response and st.session_state.debug_mode:
                                st.session_state.execution_log = response["execution_log"]
                        else:
                            # å¤„ç†å“åº”ä¸ºç©ºçš„æƒ…å†µ
                            error_message = "æŠ±æ­‰ï¼ŒæœåŠ¡å™¨æ²¡æœ‰è¿”å›æœ‰æ•ˆå“åº”ã€‚"
                            message_placeholder.markdown(error_message)
                            message_obj = {
                                "role": "assistant", 
                                "content": error_message,
                                "message_id": str(uuid.uuid4())
                            }
                    
                    # æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
                    st.session_state.messages.append(message_obj)
                        
                    # ä»å›ç­”ä¸­æå–çŸ¥è¯†å›¾è°±æ•°æ®ï¼Œdeep_research_agentç¦ç”¨æ­¤åŠŸèƒ½
                    if st.session_state.debug_mode and st.session_state.agent_type != "deep_research_agent":
                        with st.spinner("æå–çŸ¥è¯†å›¾è°±æ•°æ®..."):
                            # è·å–å½“å‰æ–°æ¶ˆæ¯çš„ç´¢å¼•ï¼Œå³æœ€åä¸€æ¡æ¶ˆæ¯
                            current_msg_index = len(st.session_state.messages) - 1
                            
                            # ä¼˜å…ˆä½¿ç”¨åç«¯è¿”å›çš„kg_data
                            kg_data = response.get("kg_data") if not use_stream else None
                            
                            # å¦‚æœåç«¯æ²¡æœ‰è¿”å›kg_dataï¼Œå°è¯•ä»å›ç­”ä¸­æå–ï¼Œå¹¶ä¼ é€’ç”¨æˆ·æŸ¥è¯¢
                            if not kg_data or len(kg_data.get("nodes", [])) == 0:
                                answer_content = message_obj["content"]
                                kg_data = get_knowledge_graph_from_message(answer_content, prompt)
                            
                            if kg_data and len(kg_data.get("nodes", [])) > 0:
                                # æ›´æ–°è¯¥æ¶ˆæ¯çš„kg_data
                                st.session_state.messages[current_msg_index]["kg_data"] = kg_data
                                
                                # æ›´æ–°å½“å‰å¤„ç†çš„å›¾è°±æ¶ˆæ¯ç´¢å¼•ä¸ºæœ€æ–°æ¶ˆæ¯çš„ç´¢å¼•
                                st.session_state.current_kg_message = current_msg_index
                                
                                # è‡ªåŠ¨åˆ‡æ¢åˆ°çŸ¥è¯†å›¾è°±æ ‡ç­¾
                                st.session_state.current_tab = "çŸ¥è¯†å›¾è°±"
                                st.rerun()
                            else:
                                if st.session_state.agent_type != "deep_research_agent":
                                    st.warning("æ— æ³•æå–çŸ¥è¯†å›¾è°±æ•°æ®")
                except Exception as e:
                    st.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
                    traceback.print_exc()
                finally:
                    # ç¡®ä¿è¯·æ±‚å¤„ç†å®Œæˆåé‡Šæ”¾é”
                    st.session_state.processing_lock = False
                    
            st.rerun()

def clear_chat_with_lock_reset():
    """æ¸…é™¤èŠå¤©å¹¶é‡ç½®å¤„ç†é”"""
    # é‡ç½®å¤„ç†é”
    st.session_state.processing_lock = False
    # è°ƒç”¨åŸå§‹æ¸…é™¤å‡½æ•°
    clear_chat()